{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. How to handle missing data in regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Understanding Missing Data\n",
    "\n",
    "Before deciding how to handle missing data, it's important to understand the nature and potential reasons for the missingness. Missing data can be categorized into three types:\n",
    "\n",
    "- **Missing Completely at Random (MCAR):** The probability of missingness is the same for all observations, and missing values are not related to any other observed or unobserved data.\n",
    "\n",
    "- **Missing at Random (MAR):** The missingness is related to observed data, but not to the unobserved data.\n",
    "\n",
    "- **Missing Not at Random (MNAR):** The missingness is related to the unobserved data. In such cases, the missing data itself is informative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Common Techniques to Handle Missing Data\n",
    "\n",
    "### 1.2.1 Deletion\n",
    "\n",
    "- **Listwise Deletion (Complete Case Analysis)**\n",
    "\n",
    "    - **Description:** Remove all observations with any missing values.\n",
    "\n",
    "    - **Pros:**\n",
    "\n",
    "        - Simple to implement.\n",
    "        \n",
    "        - Keeps the dataset consistent across variables.\n",
    "            \n",
    "    - **Cons:**\n",
    "\n",
    "        - Can lead to a significant loss of data, especially if many observations have missing values.\n",
    "\n",
    "        - May introduce bias if the missing data is not MCAR.\n",
    "\n",
    "- **Pairwise Deletion**\n",
    "\n",
    "    - **Description:** Only remove observations with missing values for specific analyses or calculations.\n",
    "\n",
    "    - **Pros:**\n",
    "\n",
    "        - Preserves more data than listwise deletion.\n",
    "\n",
    "    - **Cons:**\n",
    "\n",
    "        - Inconsistent sample size across different analyses.\n",
    "\n",
    "        - May lead to biased estimates if the data is not MCAR.\n",
    "\n",
    "### 1.2.2. Imputation\n",
    "\n",
    "- **Mean/Median/Mode Imputation**\n",
    "\n",
    "    - **Description:** Replace missing values with the mean, median, or mode of the observed data for each variable.\n",
    "\n",
    "    - **Pros:**\n",
    "\n",
    "        - Simple and quick to implement.\n",
    "\n",
    "    - **Cons:**\n",
    "\n",
    "        - Does not account for the relationships between variables, leading to underestimated variability.\n",
    "        \n",
    "        - Can introduce bias if the data is not MCAR or MAR.\n",
    "\n",
    "- **K-Nearest Neighbors (KNN) Imputation**\n",
    "\n",
    "    - **Description:** Use the average of the nearest $k$ neighbors to impute missing values based on feature similarity.\n",
    "\n",
    "    - **Pros:**\n",
    "\n",
    "        - Accounts for relationships between variables.\n",
    "        \n",
    "        - More accurate than mean/median/mode imputation.\n",
    "\n",
    "    - **Cons:**\n",
    "\n",
    "        - Computationally intensive, especially with large datasets.\n",
    "\n",
    "        - Choice of $k$ and distance metric can affect results.\n",
    "\n",
    "- **Regression Imputation**\n",
    "\n",
    "    - **Description:** Predict missing values using regression models based on other variables in the dataset.\n",
    "\n",
    "    - **Pros:**\n",
    "\n",
    "        - Accounts for relationships between variables.\n",
    "\n",
    "        - Useful when relationships between variables are linear.\n",
    "\n",
    "    - **Cons:**\n",
    "\n",
    "        - Can underestimate variability.\n",
    "\n",
    "        - Assumes linearity unless using non-linear models.\n",
    "\n",
    "- **Multiple Imputation**\n",
    "\n",
    "    - **Description:** Create multiple imputed datasets, analyze each, and combine results to account for uncertainty in imputations.\n",
    "\n",
    "    - **Pros:**\n",
    "\n",
    "        - Provides robust estimates by incorporating uncertainty in the imputation process.\n",
    "\n",
    "        - Suitable for complex datasets and missing data mechanisms.\n",
    "\n",
    "    - **Cons:**\n",
    "\n",
    "        - Computationally intensive.\n",
    "\n",
    "        - More complex to implement and interpret.\n",
    "\n",
    "- **Interpolation and Extrapolation**\n",
    "\n",
    "    - **Description:** Use interpolation for missing values in time-series data based on observed values before and after the gap.\n",
    "\n",
    "    - **Pros:**\n",
    "\n",
    "        - Suitable for time-series data with trends or patterns.\n",
    "\n",
    "    - **Cons:**\n",
    "\n",
    "        - Can be inaccurate if data is highly volatile or non-linear.\n",
    "\n",
    "### 1.2.3. Advanced Techniques\n",
    "\n",
    "- **Using Machine Learning Models:**\n",
    "\n",
    "    - **Description:** Use machine learning models to predict and impute missing values based on other features.\n",
    "\n",
    "    - **Pros:**\n",
    "\n",
    "        - Flexible and can model complex relationships.\n",
    "\n",
    "    - **Cons:**\n",
    "\n",
    "        - Computationally intensive and requires careful tuning and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Implementing Missing Data Techniques in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a real dataset to illustrate various techniques for handling missing data. We'll use the Titanic dataset, which is readily available in the seaborn library. This dataset contains information about the passengers on the Titanic, including whether they survived, their age, and other attributes. The dataset has missing values, which makes it a good example for demonstrating different imputation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and Explore the Titanic Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "\n",
      "Missing values per column:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyzing Missing Data**\n",
    "\n",
    "The output will show the structure of the dataset and indicate which columns have missing values. Typically, `age`, `embarked`, `deck`, and `embark_town` have missing values in the Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Handling Missing Data\n",
    "\n",
    "Let's go through several techniques to handle these missing values.\n",
    "\n",
    "#### 1.3.1.1. **Deletion Methods**\n",
    "\n",
    "- **Listwise Deletion:** Remove all rows with any missing values\n",
    "    \n",
    "    - **Pros and Cons:** This method is straightforward but may result in a significant loss of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Listwise deletion:\n",
      "(182, 15)\n"
     ]
    }
   ],
   "source": [
    "# Listwise deletion\n",
    "df_listwise = df.dropna()\n",
    "\n",
    "# Check the size of the new DataFrame\n",
    "print(\"\\nListwise deletion:\")\n",
    "print(df_listwise.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1.2. **Imputation Methods**\n",
    "\n",
    "- **Mean Imputation**\n",
    "\n",
    "    - Replace missing age values with the mean age\n",
    "\n",
    "    - **Pros and Cons:** Easy to implement but does not consider variability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean imputation for 'age':\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_636718/218974129.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_mean_imputed['age'].fillna(df_mean_imputed['age'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Mean imputation for 'age'\n",
    "df_mean_imputed = df.copy()\n",
    "df_mean_imputed['age'].fillna(df_mean_imputed['age'].mean(), inplace=True)\n",
    "\n",
    "# Check for missing values in 'age'\n",
    "print(\"\\nMean imputation for 'age':\")\n",
    "print(df_mean_imputed['age'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **K-Nearest Neighbors (KNN) Imputation**\n",
    "\n",
    "    - Use KNN to impute missing values based on similar rows\n",
    "\n",
    "    - **Pros and Cons:** Captures relationships between variables but can be computationally intensive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN imputation for 'age':\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Select numeric columns for KNN imputation\n",
    "df_numeric = df[['age', 'fare', 'pclass', 'sibsp', 'parch']]\n",
    "\n",
    "# Apply KNN imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "df_knn_imputed = df_numeric.copy()\n",
    "df_knn_imputed.iloc[:, :] = knn_imputer.fit_transform(df_numeric)\n",
    "\n",
    "# Check for missing values in 'age'\n",
    "print(\"\\nKNN imputation for 'age':\")\n",
    "print(df_knn_imputed['age'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Regression Imputation**\n",
    "\n",
    "    - Predict missing age values using linear regression based on other features:\n",
    "\n",
    "    - **Pros and Cons:** Utilizes relationships between variables but assumes linearity unless using non-linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression imputation for 'age':\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data for regression imputation\n",
    "age_known = df[df['age'].notnull()]\n",
    "age_unknown = df[df['age'].isnull()]\n",
    "\n",
    "# Independent variables\n",
    "X_known = age_known[['pclass', 'sibsp', 'parch', 'fare']]\n",
    "X_unknown = age_unknown[['pclass', 'sibsp', 'parch', 'fare']]\n",
    "\n",
    "# Dependent variable\n",
    "y_known = age_known['age']\n",
    "\n",
    "# Fit regression model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_known, y_known)\n",
    "\n",
    "# Predict missing ages\n",
    "predicted_ages = regressor.predict(X_unknown)\n",
    "\n",
    "# Impute predicted ages\n",
    "df_regression_imputed = df.copy()\n",
    "df_regression_imputed.loc[df['age'].isnull(), 'age'] = predicted_ages\n",
    "\n",
    "# Check for missing values in 'age'\n",
    "print(\"\\nRegression imputation for 'age':\")\n",
    "print(df_regression_imputed['age'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1.3. **Advanced Techniques**\n",
    "\n",
    "- **Multiple Imputation**\n",
    "\n",
    "    - Implement multiple imputation to account for uncertainty in the imputation process:\n",
    "\n",
    "    - **Pros and Cons:** Provides robust estimates but is computationally intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiple imputation for 'age':\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Use IterativeImputer for multiple imputation\n",
    "iterative_imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "df_multiple_imputed = df_numeric.copy()\n",
    "df_multiple_imputed.iloc[:, :] = iterative_imputer.fit_transform(df_numeric)\n",
    "\n",
    "# Check for missing values in 'age'\n",
    "print(\"\\nMultiple imputation for 'age':\")\n",
    "print(df_multiple_imputed['age'].isnull().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "margaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
