{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a widely used statistical method for modeling binary classification problems. It is distinct from linear regression in its purpose and underlying mathematical framework, focusing on predicting categorical outcomes rather than continuous values. Hereâ€™s an overview of logistic regression, its differences from linear regression, and typical use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Overview of Logistic Regression\n",
    "\n",
    "**Purpose**\n",
    "\n",
    "Logistic regression is used to model the probability that a given input belongs to a particular category. It is particularly suited for binary classification tasks where the outcome is categorical, such as yes/no, true/false, or success/failure.\n",
    "\n",
    "**Logistic Function**\n",
    "\n",
    "The key component of logistic regression is the logistic function (also known as the sigmoid function), which maps any real-valued number into a value between 0 and 1:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Where \\( z \\) is a linear combination of the input features:\n",
    "\n",
    "$$\n",
    "z = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n\n",
    "$$\n",
    "\n",
    "**Logistic Regression Model**\n",
    "\n",
    "The logistic regression model predicts the probability \\( P(y = 1 \\mid x) \\) as:\n",
    "\n",
    "$$\n",
    "P(y = 1 \\mid x) = \\sigma(z) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n)}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $P(y = 1 \\mid x)$ is the probability of the outcome being 1, given the input features $x$.\n",
    "- $\\beta_0$ is the intercept.\n",
    "- $\\beta_1, \\beta_2, \\ldots, \\beta_n$ are the coefficients for the input features $x_1, x_2, \\ldots, x_n$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Differences Between Logistic and Linear Regression\n",
    "\n",
    "1. **Nature of the Dependent Variable**\n",
    "\n",
    "    - **Linear Regression:** Used for predicting a continuous dependent variable.\n",
    "    \n",
    "    - **Logistic Regression:** Used for predicting a categorical dependent variable, typically binary.\n",
    "\n",
    "2. **Output Interpretation**\n",
    "\n",
    "    - **Linear Regression:** Directly predicts the outcome value, which can range from $-\\infty$ to $+\\infty$.\n",
    "    \n",
    "    - **Logistic Regression:** Predicts the probability of the outcome belonging to a certain class, which ranges between 0 and 1.\n",
    "\n",
    "3. **Link Function**\n",
    "\n",
    "    - **Linear Regression:** Uses an identity link function, meaning the prediction is a direct linear combination of inputs.\n",
    "    \n",
    "    - **Logistic Regression:** Uses a logistic (sigmoid) link function to map predictions to probabilities.\n",
    "\n",
    "\n",
    "4. **Cost Function**\n",
    "\n",
    "    - **Linear Regression:** Typically uses Mean Squared Error (MSE) as the cost function.\n",
    "  \n",
    "  $$\n",
    "  \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "  $$\n",
    "\n",
    "  Where:\n",
    "  - $n$ is the number of observations.\n",
    "  - $y_i$ is the actual value.\n",
    "  - $\\hat{y}_i$ is the predicted value.\n",
    "\n",
    "    - **Logistic Regression:** Uses the log-loss (or cross-entropy loss) function, which is suited for classification tasks.\n",
    "\n",
    "  $$\n",
    "  \\text{Log-Loss} = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\n",
    "  $$\n",
    "\n",
    "  Where:\n",
    "  - $m$ is the number of instances.\n",
    "  - $y_i$ is the true label for instance $i$ (0 or 1).\n",
    "  - $p_i$ is the predicted probability for instance $i$ that $y = 1$.\n",
    "\n",
    "5. **Optimization**\n",
    "    - **Linear Regression:** Can be solved using analytical methods or gradient descent.\n",
    "    - **Logistic Regression:** Typically solved using iterative optimization algorithms like gradient descent due to the non-linear nature of the cost function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Typical Use Cases for Logistic Regression\n",
    "\n",
    "1. **Binary Classification**\n",
    "\n",
    "    - Logistic regression is the go-to model for binary classification problems, such as spam detection (spam vs. not spam), disease diagnosis (positive vs. negative), and customer churn (churn vs. no churn).\n",
    "\n",
    "2. **Credit Scoring**\n",
    "\n",
    "    - Predicting the likelihood of default on a loan based on borrower characteristics.\n",
    "\n",
    "3. **Medical Diagnosis**\n",
    "\n",
    "    - Determining the presence or absence of a disease based on patient data.\n",
    "\n",
    "4. **Marketing**\n",
    "\n",
    "    - Predicting customer purchase behavior (buy vs. not buy) based on demographic and behavioral data.\n",
    "\n",
    "5. **Fraud Detection**\n",
    "\n",
    "    - Identifying fraudulent transactions based on transaction patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Implementing Logistic Regression in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Titanic dataset includes information about the passengers on the Titanic, such as their age, sex, class, and whether they survived. We'll use logistic regression to predict the likelihood of survival (`survived` column) based on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 8  5]\n",
      " [ 9 15]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.62      0.53        13\n",
      "           1       0.75      0.62      0.68        24\n",
      "\n",
      "    accuracy                           0.62        37\n",
      "   macro avg       0.61      0.62      0.61        37\n",
      "weighted avg       0.65      0.62      0.63        37\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.6216216216216216\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = sns.load_dataset('titanic').dropna(subset=['age', 'embarked', 'fare', 'deck'])\n",
    "\n",
    "# Preprocessing: Convert categorical variables to numerical\n",
    "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
    "df['embarked'] = df['embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "df['deck'] = df['deck'].map({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6})\n",
    "\n",
    "# Define the feature matrix X and target vector y\n",
    "X = df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'deck']]\n",
    "y = df['survived']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and fit the logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "margaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
